NPMLEst_boot[i] <- NPMLEstimateFunction(N,cend)[[3]]
}
NPMLEst_boot
501-15-37
448-12-76
360-7-65
288-7-65
216-18-34
164-22-14
128-7-21
100-21-7
71-10-11
50-6-4
72-10-11
51-7-9
25-11-4
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
table(obs,N)
idx.new <- which(N!=0)
obs.new <- obs[idx.new]
N.new <- N[idx.new]
N <- N.new
cen <- obs.new
censor.rate <- sum(cen)/length(cen)
N
cen
length(N)
length(cen)
table(N,cen)
rwoSums(table(N,cen))
table(N,cen)
as.data.farme(table(N,cen))
as.data.frame(table(N,cen))
as.data.frame(table(N,cen))
new.data <- as.data.frame(table(N,cen))
new.data
risk <- rep(0,17)
max(n)
max(N)
length(N)
head(new.data)
risk <- rep(0,max(N))
for(i in 1:max(N)){
if(i==1){
idx <- which(new.data[,1]==i)
remove <- sum(new.data[idx,3])
risk[i] <- length(N)-remove
}else{
idx <- which(new.data[,1]==i)
remove <- sum(new.data[idx,3])
risk[i] <- risk[i-1]-remove
}
}
censor.rate <- sum(cen)/length(cen)
risk
risk
max(n)
max(N)
length(N)
for(i in 1:max(N)){
if(i==1){
idx <- which(new.data[,1]==i)
remove <- sum(new.data[idx,3])
risk[i] <- length(N)
}else{
idx <- which(new.data[,1]==i)
remove <- sum(new.data[idx,3])
risk[i] <- risk[i-1]-remove
}
}
risk
N
head(new.data)
new.data
76/449
table(N,cen)
table(N,cen)[,2]
table(N,cen)[,1]
sur.data <- cbind(table(N,cen),risk)
sur.data
K.estimate <- sur.data[,2]/risk
K.estiamte
K.estimate
K.estimate
plot(K.estimate)
round(K.estimate)
round(K.estimate,2)
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
table(obs,N)
idx.new <- which(N!=0)
obs.new <- obs[idx.new]
N.new <- N[idx.new]
N <- N.new
cen <- obs.new
censor.rate <- sum(cen)/length(cen)
library(devtools)
library(PAV)
NPML.estimate <- NPMLEstimateFunction(N,cen)
UU <- NPML.estimate[[1]]
pp <- NPML.estimate[[2]]
UU
preg.probability.est <- NPML.estimate[[3]]
preg.probability.est
mean.estimate <- UU%*%pp
mean.estimate
Var.estimate <- (UU-mean.estimate)^2%*%pp
Var.estimate
UU-mean.estimate
mean.estimate <- sum(UU%*%pp)
mean.estimate
ar.estimate <- sum((UU-mean.estimate)^2%*%pp)
var.estimate <- sum((UU-mean.estimate)^2%*%pp)
var.estiamte
var.estimate
mean.estimate
var.estimate
M <- mean.estimate*(1-mean.estimate)/var.estimate-1
M
var.estimate
x <- seq(0,1,0.0001)
head(x)
y <- dbeta(x,alpha,beta)
alpha <- mean.estimate*M
beta <- (1-mean.estimate)*M
x <- seq(0,1,0.0001)
y <- dbeta(x,alpha,beta)
head(y)
plot(x,y,type='l')
plot(x,y,type='l',main="beta distribution density estimate")
head(data)
head(data.baseline)
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
table(obs,N)
idx.new <- which(N!=0)
obs.new <- obs[idx.new]
N.new <- N[idx.new]
N <- N.new
cen <- obs.new
censor.rate <- sum(cen)/length(cen)
library(devtools)
library(PAV)
NPML.estimate <- NPMLEstimateFunction(N,cen)
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
table(obs,N)
idx.new <- which(N!=0)
obs.new <- obs[idx.new]
N.new <- N[idx.new]
head(data)
head(data.baseline)
head(cbind(N,obs))
head(ID)
head(data$ID)
ID[1]
head(new.data)
length(N)
length(obs)
data.temp <- cbind(ID,obs,N)
head(data)
head(data.temp)
head(data.baseline)
dim(data.baseline)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
head(data.com)
data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
library(tidyverse)
data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
head(dta.com)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
head(data.com)
data.com <- data.com[idx,]
dim(data.com)
dim(data.com)
tbale(obs,N)
table(obs,N)
table(N)
length(idx)
nrow(data.com)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
library(tidyverse)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
dim(data.com)
table(data.com$N)
501-52
idx <- which(data.com$N!=0)
length(idx)
data.com <- data.com[idx,]
head(data.com)
dim(data.com)
source('~/GoogleDrive/project/Tom/mixture_approach_estimate_population_value/mixture_approach/code/logistic_support.R', echo=TRUE)
head(data)
head(data.com)
idx.2 <- which(data.com$obs==1)
data.com <- data.com[idx.2]
data.com <- data.com[idx.2,]
dim(data.com)
table(obs,N)
table(data.com$obs)
table(obs)
dim(data.com)
head(data.com)
tol <- 1e-07
maxit <- 500
param.start=c(0,0,0)
standard_logistic(data.com$N,cbind(data.com$age_average,data.com$age_diff),param.start,tol,maxit)
library(car)
standard_logistic(data.com$N,cbind(data.com$age_average,data.com$age_diff),param.start,tol,maxit)
source('~/GoogleDrive/project/Tom/mixture_approach_estimate_population_value/mixture_approach/code/logistic_NPML.R', echo=TRUE)
head(N)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
library(tidyverse)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
idx <- which(data.com$N!=0)
data.com <- data.com[idx,]
idx.2 <- which(data.com$obs==1)
data.com.obs <- data.com[idx.2,]
dim(data.com)
dim(data.com.obs)
head(data.com)
NPML_logistic_function(data.com$N,cbind(data.com$age_average,data.com$age_diff),tol,maxit,K,data.com$obs)
source('~/GoogleDrive/project/Tom/mixture_approach_estimate_population_value/mixture_approach/code/logistic_NPML.R', echo=TRUE)
NPML_logistic_function(data.com$N,cbind(data.com$age_average,data.com$age_diff),tol,maxit,K,data.com$obs)
dim(data.com)
K= 449
NPML_logistic_function(data.com$N,cbind(data.com$age_average,data.com$age_diff),tol,maxit,K,data.com$obs)
u_new_min = 0
u_new_max = 1.5
NPML_logistic_function(data.com$N,cbind(data.com$age_average,data.com$age_diff),tol,maxit,K,data.com$obs)
NPML_logistic_function(data.com$N,cbind(data.com$age_average,data.com$age_diff),tol,maxit,K,data.com$obs)
param
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
head(data)
dim(data)
head(data.baseline)
dim(data.baseline)
dim(data)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
table(obs,N)
sum(table(obs,N))
head(N)
head(obs)
sum(N)
sum(N+1)
head(data.baseline)
head(data)
data[1:100,]
data[1:200,]
data[90:200,]
data[1:89,]
ID
ID <<- 1
ID[1]
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
i <- 1
idx <- which(data$ID==ID[i])
data[idx,]
length(idx)
data[idx[100:"10045"],]
data[idx[100:145],]
obs[1]
N[1]
N
i <- 2
idx <- which(data$ID==ID[i])
data[idx,]
N
obs
i <- 3
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
obs
data[idx,]
N
obs
i <- 4
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
data[idx,]
table(obs,N)
sum(N)
library(sas7bdat)
setwd('/users/hzhang1/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
n.sub <- length(table(data$ID))
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
data.temp <- cbind(ID,obs,N)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
head(data.com)
head(data.com$N)
range(data.com$N)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
data.temp <- cbind(ID,obs,N)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
head(data.com)
table(obs,N)
library(tidyverse)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
idx <- which(data.com$N!=0)
data.com <- data.com[idx,]
dim(data.com)
head(data.com)
data.temp <- cbind(ID,obs,N)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
library(tidyverse)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
###############take out the first cycle
idx <- which(data.com$N!=0)
data.clean <- data.com[idx,]
dim(data.clean)
head(data.clean)
data.clean[1:10,]
data.clean[1:20,]
sum(data.clean)
sum(data.clean$N)
n.couple <- nrow(data.clean)
n.cycle <- sum(data.clean$N)
temp <- 0
for(i in 1:n.couple){
if(data.clean$obs==1){
Y[temp] = 1
}
age_averge.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_average[i]
age_diff.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_diff[i]
temp <- temp+data.clean$N[i]
}
n.couple <- nrow(data.clean)
n.cycle <- sum(data.clean$N)
Y <- rep(0,n.cycle)
age_averge.cycle <- rep(0,n.cycle)
age_diff.cycle <- rep(0,n.cycle)
temp <- 0
for(i in 1:n.couple){
print(i)
if(data.clean$obs==1){
Y[temp] = 1
}
age_averge.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_average[i]
age_diff.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_diff[i]
temp <- temp+data.clean$N[i]
}
warnings()
n.couple <- nrow(data.clean)
n.cycle <- sum(data.clean$N)
Y <- rep(0,n.cycle)
age_averge.cycle <- rep(0,n.cycle)
age_diff.cycle <- rep(0,n.cycle)
temp <- 0
for(i in 1:n.couple){
print(i)
if(data.clean$obs[i]==1){
Y[temp] = 1
}
age_averge.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_average[i]
age_diff.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_diff[i]
temp <- temp+data.clean$N[i]
}
head(Y)
Y[1:10]
head(data.clean)
age_averge.cycle[1:10]
model.logistic <- glm(Y~age_averge.cycle+age_diff.cycle)
summary(model.logistic)
n.cycle
exp(0.355982)/(1+exp(0.355982))
confint(model.logistic)
library(lme4)
model.mix.logistic <- glmer(Y~(1|data.clean$ID)+age_averge.cycle+age_diff.cycle,family = binomial)
idx <- which(data.com$N!=0)
data.clean <- data.com[idx,]
dim(data.clean)
n.couple <- nrow(data.clean)
n.cycle <- sum(data.clean$N)
Y <- rep(0,n.cycle)
age_averge.cycle <- rep(0,n.cycle)
age_diff.cycle <- rep(0,n.cycle)
ID.cycle <- rep(0,n.cycle)
temp <- 0
for(i in 1:n.couple){
print(i)
if(data.clean$obs[i]==1){
Y[temp] = 1
}
age_averge.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_average[i]
age_diff.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_diff[i]
ID.cycle[temp+(1:data.clean$N[i])] <- data.clean$ID[i]
temp <- temp+data.clean$N[i]
}
model.logistic <- glm(Y~age_averge.cycle+age_diff.cycle)
summary(model.logistic)
model.mix.logistic <- glmer(Y~(1|data.clean$ID)+age_averge.cycle+age_diff.cycle,family = binomial)
model.mix.logistic <- glmer(Y~(1|ID.cycle)+age_averge.cycle+age_diff.cycle,family = binomial)
summary(model.mix.logistic)
head(ID.cycle)
confint(model.logistic)
confint(model.mix.logistic)
seq(0,1,10)
seq(0,1,0.1)
length(seq(0,1,0.1))
y <- 100
K <- length(y)
uu <- seq(0,1,by = 1/(K-1))
length(uu)
K
y <- rep(0,100)
K
uu <- seq(0,1,by = 1/(K-1))
length(uu)
k
K
y
K <- length(y)
uu <- seq(0,1,by = 1/(K-1))
length(uu)
