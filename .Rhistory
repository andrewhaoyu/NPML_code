tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
crossprod(uu_new,w)
LikeliResult[1:l]
LikeliResult_temp =LikeliResult[1]
y_sm = y+0.02
uu0 = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta0 = c(0,0)
# uu_old = u
# beta_old = c(beta1,beta2)
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
LikeliResult[1:l]
LikeliResult_temp
crossprod(uu_new,w)
crossprod(u,w)
mean(u)
n = 500
x1 = rnorm(n,1,4)
#x2 = rnorm(n,31,4.2)
x2 = rnorm(n,0,1)
obs.ratio <- 1
obs <- rbinom(n,1,obs.ratio)
u = rnorm(n,0,2)
beta1 = 0.01
beta2 = 0.02
p = logit_inver(u+beta1*x1+beta2*x2)
CensorGeomFun <- function(p,censor.rate){
temp = 1
while(1!=0){
cen <- rbinom(1,1,(1-censor.rate))
x <- rbinom(1,1,p)
if(cen!=0){
if(x==0){
temp = temp + 1
}else if(x==1){
result = (list(temp,x))
break;
}
}else if(cen==0){
result = (list(temp,x))
break;
}
}
return(result)
}
y = rep(0,n)
obs = rep(0,n)
for(i in 1:n){
result = CensorGeomFun(p[i],censor.rate = 0.2)
y[i] = result[[1]]
obs[i] = result[[2]]
}
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 1500
# uu_old = u
# beta_old = c(beta1,beta2)
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
l-1
plot(LikeliResult[1:(l-1)])
obs
N
y
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 1500
# uu_old = u
# beta_old = c(beta1,beta2)
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
plot(LikeliResult[1:(l-1)])
steps
step
crossprod(uu_new,w)
beta
beta_new
tail(LikeliResult[1:(l-1)])
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 3000
# uu_old = u
# beta_old = c(beta1,beta2)
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
plot(LikeliResult[1:(l-1)])
tail(LikeliResult[1:(l-1)])
Mstep <- function(uu_old,beta_old,x,y,ww,alpha_x,obs){
step <- 200
n <- length(y)
alpha <- 1/(n*10)
tol <- alpha
ComLik0 = ComLikfun(y,x,uu_old,beta_old,ww,obs)
#Likelihood_old <- Likelihoodfun(y,x,uu_old,beta_old,ww)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
#print(uu_beta_old)
uu_new = uu_old+alpha*gr_u_fun(uu_old,y,ww,beta_old,x,n,obs)
beta_new <- beta_old+(alpha_x/100)*gr_b_fun(uu_new,y,ww,beta_old,x,n,obs)
######test the Likelihood for a few steps
if(l%%10==0){
ComLik_new = ComLikfun(y,x,uu_new,beta_new,ww,obs)
if(ComLik_new>ComLik0){
break
}else if(ComLik_new<=ComLik0){
uu_new = uu_old
beta_new = beta_old
alpha = alpha/2
alpha_x = alpha_x/2
}
}
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
}
return(list(uu_new,beta_new,l))
}
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 3000
# uu_old = u
# beta_old = c(beta1,beta2)
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
l
plot(LikeliResult[1:l])
tail(LikeliResult[1:l])
beta_new
crossprod(uu_new,w)
setwd('/Users/zhangh24/GoogleDrive/project/Tom/mixture_approach_estimate_population_value/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
library(data.table)
data.sum <- as.data.frame(fread('./data/LIFE_DATA/summary_table.csv',header=T))
data.sum <- data.sum[-1,]
data.sum[,4] <- as.numeric(data.sum[,4])
data.sum[,3] <- as.numeric(data.sum[,3])
data.sum[,2] <- as.numeric(data.sum[,2])
data.sum$still_in_study <- data.sum[,4]-data.sum[,3]-data.sum[,2]
colnames(data.sum)[6] <- "Still in study"
n.sub <- length(table(data$ID))
data.clean <- data.sum[,c(1,2,3,6)]
data.m <- melt(data.clean,id="Number of menstrual cycles")
colnames(data.m)[1] <- "nmc"
colnames(data.m)[2] <- "Current_status"
ID <- unique(data$ID)
ID <- sort(ID)
setwd('/Users/zhangh24/GoogleDrive/project/Tom/mixture_approach_estimate_population_value/mixture_approach')
data <- read.sas7bdat('./data/LIFE_DATA/dailycycle.sas7bdat')
data.baseline <- read.sas7bdat('./data/LIFE_DATA/baseline.sas7bdat')
library(data.table)
data.sum <- as.data.frame(fread('./data/LIFE_DATA/summary_table.csv',header=T))
data.sum <- data.sum[-1,]
data.sum[,4] <- as.numeric(data.sum[,4])
data.sum[,3] <- as.numeric(data.sum[,3])
data.sum[,2] <- as.numeric(data.sum[,2])
data.sum$still_in_study <- data.sum[,4]-data.sum[,3]-data.sum[,2]
colnames(data.sum)[6] <- "Still in study"
n.sub <- length(table(data$ID))
data.clean <- data.sum[,c(1,2,3,6)]
data.m <- melt(data.clean,id="Number of menstrual cycles")
colnames(data.m)[1] <- "nmc"
colnames(data.m)[2] <- "Current_status"
library(ggplot2)
ID <- unique(data$ID)
ID <- sort(ID)
obs <- rep(0,n.sub)
N <- rep(0,n.sub)
for(i in 1:n.sub){
print(i)
idx <- which(data$ID==ID[i])
cbind(data[idx,]$preg,data[idx,]$method5)
obs[i] <- max(data[idx,]$preg,na.rm=T)
N[i] <- max(data[idx,]$method5,na.rm=T)
}
data.temp <- cbind(ID,obs,N)
data.com <- merge(data.temp,data.baseline,by.x="ID",by.y="ID")
library(tidyverse)
library(dplyr)
data.com <- data.com %>% mutate(
age_average = (Age_m+Age_f)/2,
age_diff = abs(Age_m-Age_f)/2
)
data.clean <- data.com
data.clean$N <- data.com$N+1
dim(data.clean)
n.couple <- nrow(data.clean)
n.cycle <- sum(data.clean$N)
Y <- rep(0,n.cycle)
age_averge.cycle <- rep(0,n.cycle)
age_diff.cycle <- rep(0,n.cycle)
ID.cycle <- rep(0,n.cycle)
temp <- 0
for(i in 1:n.couple){
print(i)
if(data.clean$obs[i]==1){
Y[temp] = 1
}
age_averge.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_average[i]
age_diff.cycle[temp+(1:data.clean$N[i])] <- data.clean$age_diff[i]
ID.cycle[temp+(1:data.clean$N[i])] <- data.clean$ID[i]
temp <- temp+data.clean$N[i]
}
###############logistic regression adjusting for age average and age difference
model.logistic <- glm(Y~age_averge.cycle+age_diff.cycle)
summary(model.logistic)
confint(model.logistic)
##############mixed effect logistic regression allowing for sample difference
library(lme4)
model.mix.logistic <- glmer(Y~(1|ID.cycle)+age_averge.cycle+age_diff.cycle,family = binomial)
summary(model.mix.logistic)
#############NPML model
# uu0 = seq(summary(model.logistic)$coefficients[1,1]-5,
#           summary(model.logistic)$coefficients[1,1]+5,
#           10/(n-1))
#
# beta0 = summary(model.logistic)$coefficients[2:3,1]
#model.NPMLlog <- NPMLLogFun(y=data.clean$N,x=cbind(data.clean$age_average,data.clean$age_diff),uu0,beta0)
tl <- c(0.005)
max_likelihood <- rep(0,length(tl))
beta_result <- matrix(0,length(tl),2)
mu_result <- matrix(0,length(tl),1)
max_step <- rep(0,length(tl))
s =1
n <- nrow(data.clean)
y=data.clean$N;
x=cbind(data.clean$age_average,data.clean$age_diff);
x <- as.matrix(x)
step = 2000
y_sm = y
y_sm[y_sm==1] = y_sm[y_sm==1] + tl[s]
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
#uu_old = log((1/y_sm)/(1-1/y_sm))
beta_old = summary(model.logistic)$coefficients[2:3,1]
tol = 1e-04
n = length(y)
w = rep(1/n,n)
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w,obs)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w,obs)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x,obs)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
l
plot(LikeliResult[1:l])
crossprod(uu_old,w)
uu_new
w
l
library(boot)
library(boot)
?boot.ci
library(bootstrap)
install.packges("bootstrap")
install.packages("bootstrap")
?bcanon
?bcanon
?bootstrap
BetaEst <- ParaBetaEstimateFunction(N,cen,begin)[[2]]
bootdata <- data.frame(N=N,cen=cen)
set.seed(i1)
