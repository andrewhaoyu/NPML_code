beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
l
n = 500
x1 = rnorm(n,1,4)
x2 = rnorm(n,31,4.2)
u = rnorm(n,0,2)
beta1 = 0.01
beta2 = 0.02
p = logit_inver(u+beta1*x1+beta2*x2)
y = rgeom(n,p)+1
y_sm = y+1
uu0 = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta0 = c(0,0)
x = cbind(x1,x2)
#model.NPMLlog <- NPMLLogFun(y=y,x=cbind(x1,x2),uu0,beta0)
ObsLikfun <- function(y,x,uu_old,beta_old,w){
n <- length(y)
result <- rep(0,n)
xb = x%*%beta_old
for(i in 1:n){
result[i] <- log(sum(w*logit_inver(uu_old+xb[i])*(1-logit_inver(uu_old+xb[i]))^(y[i]-1)))
}
return(sum(result))
}
ComLikfun <- function(y,x,uu_old,beta_old,ww){
xb = x%*%beta_old
n <- length(y)
temp_mat = matrix(0,n,n)
for(i in 1:n){
temp_mat[i,] = (uu_old+xb[i]-y[i]*log(1+exp(uu_old+xb[i])))
}
return(sum(temp_mat*ww))
}
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 1500
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
l
w
crossprod(w,uu)
crossprod(w,uu_new)
mean(u)
n = 500
x1 = rnorm(n,1,4)
x2 = rnorm(n,31,4.2)
u = rnorm(n,0,2)
beta1 = 0.01
beta2 = 0.02
p = logit_inver(u+beta1*x1+beta2*x2)
y = rgeom(n,p)+1
y_sm = y+1
uu0 = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta0 = c(0,0)
x = cbind(x1,x2)
#model.NPMLlog <- NPMLLogFun(y=y,x=cbind(x1,x2),uu0,beta0)
ObsLikfun <- function(y,x,uu_old,beta_old,w){
n <- length(y)
result <- rep(0,n)
xb = x%*%beta_old
for(i in 1:n){
result[i] <- log(sum(w*logit_inver(uu_old+xb[i])*(1-logit_inver(uu_old+xb[i]))^(y[i]-1)))
}
return(sum(result))
}
ComLikfun <- function(y,x,uu_old,beta_old,ww){
xb = x%*%beta_old
n <- length(y)
temp_mat = matrix(0,n,n)
for(i in 1:n){
temp_mat[i,] = (uu_old+xb[i]-y[i]*log(1+exp(uu_old+xb[i])))
}
return(sum(temp_mat*ww))
}
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 1500
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
Mstep <- function(uu_old,beta_old,x,y,ww,alpha_x){
step <- 200
n <- length(y)
alpha <- 1/(n*10)
tol <- alpha/10
ComLik0 = ComLikfun(y,x,uu_old,beta_old,ww)
#Likelihood_old <- Likelihoodfun(y,x,uu_old,beta_old,ww)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
#print(uu_beta_old)
uu_new = uu_old+alpha*gr_u_fun(uu_old,y,ww,beta_old,x,n)
beta_new <- beta_old+(alpha_x/100)*gr_b_fun(uu_new,y,ww,beta_old,x,n)
ComLik_new = ComLikfun(y,x,uu_new,beta_new,ww)
if(ComLik_new>ComLik0){
break
}else if(ComLik_new<=ComLik0){
uu_new = uu_old
beta_new = beta_old
alpha = alpha/2
alpha_x = alpha_x/2
}
# uu_beta_new <- c(uu_new,beta_new)
# error <- max(abs(uu_beta_new-uu_beta_old))
# if(error<tol){
#   break
# }
# uu_old <- uu_new
# beta_old <- beta_new
}
return(list(uu_new,beta_new,l))
}
n = 500
x1 = rnorm(n,1,4)
x2 = rnorm(n,31,4.2)
u = rnorm(n,0,2)
beta1 = 0.01
beta2 = 0.02
p = logit_inver(u+beta1*x1+beta2*x2)
y = rgeom(n,p)+1
y_sm = y+1
uu0 = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta0 = c(0,0)
x = cbind(x1,x2)
#model.NPMLlog <- NPMLLogFun(y=y,x=cbind(x1,x2),uu0,beta0)
ObsLikfun <- function(y,x,uu_old,beta_old,w){
n <- length(y)
result <- rep(0,n)
xb = x%*%beta_old
for(i in 1:n){
result[i] <- log(sum(w*logit_inver(uu_old+xb[i])*(1-logit_inver(uu_old+xb[i]))^(y[i]-1)))
}
return(sum(result))
}
ComLikfun <- function(y,x,uu_old,beta_old,ww){
xb = x%*%beta_old
n <- length(y)
temp_mat = matrix(0,n,n)
for(i in 1:n){
temp_mat[i,] = (uu_old+xb[i]-y[i]*log(1+exp(uu_old+xb[i])))
}
return(sum(temp_mat*ww))
}
y=y;
x=cbind(x1,x2);
x <- as.matrix(x)
step = 1500
uu_old = uu0
beta_old = beta0
tol = 0.0001
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
StepResult <- rep(0,step)
#library(PAV)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
l
tol
crossprod(w,uu_new)
beta_new
mean(u)
n <- nrow(data.clean)
y=data.clean$N;
x=cbind(data.clean$age_average,data.clean$age_diff);
x <- as.matrix(x)
step = 1000
y_sm = y+0.1
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta_old = c(0,0)
tol = 1e-04
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
tol
crossprod(w,uu_new)
beta
beta_new
summary(model.logistic)
n <- nrow(data.clean)
y=data.clean$N;
x=cbind(data.clean$age_average,data.clean$age_diff);
x <- as.matrix(x)
step = 1000
y_sm = y+0.1
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta_old = summary(model.logistic)$coefficients[2:3,1]
tol = 1e-04
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
beta_new
crossprod(w,uu_new)
n <- nrow(data.clean)
y=data.clean$N;
x=cbind(data.clean$age_average,data.clean$age_diff);
x <- as.matrix(x)
step = 1000
y_sm = y+0.05
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta_old = summary(model.logistic)$coefficients[2:3,1]
tol = 1e-04
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
beta_new
crossprod(beta_new,w)
crossprod(uu_new,w)
l
LikeliResult
y_sm = y+0.1
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta_old = summary(model.logistic)$coefficients[2:3,1]
tol = 1e-04
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
plot(LikeliResult[1:l])
LikeliResult
LikeliResult[1:l]
beta_new
#model.NPMLlog <- NPMLLogFun(y=data.clean$N,x=cbind(data.clean$age_average,data.clean$age_diff),uu0,beta0)
tl <- seq(0.02,0.1,0.02)
tl
tl <- seq(0.02,0.1,0.02)
max_likelihood <- rep(0,length(tl))
beta_result <- matrix(0,length(tl),2)
mu_result <- matrix(0,length(tl),1)
for(u in 1:length(tl)){
n <- nrow(data.clean)
y=data.clean$N;
x=cbind(data.clean$age_average,data.clean$age_diff);
x <- as.matrix(x)
step = 2000
y_sm = y+tl
uu_old = seq(min(log((1/y_sm)/(1-1/y_sm))),
max(log((1/y_sm)/(1-1/y_sm))),
(max(log((1/y_sm)/(1-1/y_sm)))-min(log((1/y_sm)/(1-1/y_sm))))/(n-1))
beta_old = summary(model.logistic)$coefficients[2:3,1]
tol = 1e-04
n = length(y)
w = rep(1/n,n)
#set the step length of gradient decent to aviod unconvergence
var.x = apply(x,2,var)
alpha_x = rep(1/n,length(beta_old))
for(i in 1:length(beta_old)){
if(var.x[i]>=1){
alpha_x[i] = alpha_x[i]/var.x[i]
}
}
LikeliResult <- rep(0,step)
for(l in 1:step){
uu_beta_old <- c(uu_old,beta_old)
print(uu_beta_old)
#print(uu_beta_old)
ww = Estep(uu_old,beta_old,x,y,w)
LikeliResult[l] <- ObsLikfun(y,x,uu_old,beta_old,w)
#rowSums(ww)
Mstep_result = Mstep(uu_old,beta_old,x,y,ww,alpha_x)
#Mstep_result = Mstep2(uu_old,beta_old,x,y,ww)
uu_new = Mstep_result[[1]]
beta_new = Mstep_result[[2]]
#StepResult[l] = Mstep_result[[3]]
uu_beta_new <- c(uu_new,beta_new)
error <- max(abs(uu_beta_new-uu_beta_old))
if(error<tol){
break
}
uu_old <- uu_new
beta_old <- beta_new
w = colSums(ww)/sum(ww)
}
max_likelihood[u] <-   LikeliResult[l]
beta_result[u,] <- beta_new
mu_result <- crossprod(uu_new,w)
}
u
